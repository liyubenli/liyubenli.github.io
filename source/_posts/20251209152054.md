---
title: unity中ui、粒子、模型渲染解决方案的思考
date: 2025-12-09 15:20:54
tags: unity
---
[“我们有一个背包界面，左边显示角色模型，右边显示背包格子。 那么3D的模型是怎么显示在2D的UI上的？ 有哪些解决方案？  怎么控制 sortingOrder，怎么理解Canvas的？ 如果用RenderTexture的方案，优缺点是什么？ 怎么处理特效某些情况下无法显示的问题以及特效显示不正确的问题（这里涉及到Shader的认知）。”](https://www.zhihu.com/question/43606447/answer/542927104)

为了解决3D模型如何和2D UI一起显示的问题，首先要了解unity中，3D模型和2D UI分别是怎么显示的。
对于3D模型而言：
1.首先要有个3D模型。每个3D模型在建模的时候，其自身有一个坐标系，即局部坐标，当这个模型被导入unity中，其导入的数据就是所有的顶点信息，包括位置、颜色、切线、法线、贴图、UV信息、拓扑关系等。其中位置即为局部坐标；法线来描述模型每个顶点的受光情况；切线为法线标识顶点位置，与法线一起构成切线空间，从而可以正确的模拟模型表面的凹凸情况；贴图可理解为模型的皮肤；UV信息用来描述贴图与顶点的对应关系；而拓扑关系则是用来描述顶点和顶点之间的关联（此处是为了方便理解，实际上贴图是独立于模型的纹理资源，一般会和模型分开导入unity中）。上述的这些顶点信息，就组成了unity当中Mesh的概念。与此同时，不同的游戏项目有着不同的美术风格，而如果想让模型适配项目本身风格，一般就要用到材质来对模型做风格化的处理。

2.然后模型要放到unity的场景里。当模型被放到场景时，其顶点位置只用模型自身坐标就无法表示了，同时模型在场景中相对建模软件会存在缩放、旋转、平移等情形，所以必须通过再次计算，先尝试缩放局部坐标，再旋转缩放后的坐标，最后平移到其在场景中的世界坐标位置，而这个计算的过程就是借由模型矩阵完成的。

3.之后需要看到模型。现时生活中，想要看到物体，那这个物体就需要进入我们的视野范围，而unity中的眼睛就是相机。相机会根据渲染层级设置、视野范围进行视锥体剔除，然后把可能需要渲染的物体列表，发送给CPU。而CPU将物体列表所涉及的Mesh数据和材质信息，按渲染顺序生成一个信息包，称其为DrawCall，并将这个指令发送给GPU。

4.GPU接收到DrawCall指令后，会统一处理所有顶点。进行顶点处理时，会先经过MVP的处理过程，即将局部坐标转换为世界坐标，再将世界坐标转换成以相机为原点的视图坐标，最后把视图坐标再转换成屏幕坐标。这样将3D转换成2D坐标后，就可以根据屏幕范围，对顶点进行裁剪，只留下最终会显示在屏幕上的坐标点。做完屏幕坐标裁剪工作之后，GPU会将剩下的顶点连接成三角形，并使用像素点填充，即光栅化过程。光栅化之后再根据顶点的深度关系、透明关系，对像素点填色，所有像素点都处理完成后，发送到屏幕帧缓冲区，最终渲染到屏幕上。需要注意的是，GPU处理顶点的过程并非无损的，而是会进行一系列的准备工作，这样会带来我们预期之外的耗时，因此在实际项目中，优化项目的一个很大的方向就是如何降低DrawCall，进而提高渲染效率。

对于2D UI而言：
1.首先要明确，unity中的2D UI，无论image、text、button等等，其本质也都是Mesh构成的。image可以看作两个三角形；text中的每一个字符是一个四边形即两个三角形。这些mesh无需我们手动操作，都是由unity自动生成，存储在canvas renderer组件中，所以，unity中的UI都是需要挂载到画布即canvas上才可以被渲染的。

2.而canvas的渲染方式又分为三种。
Screen Space - Overlay：UI 使用屏幕像素坐标（原点在左下角，x/y 对应屏幕像素），无相机依赖，直接渲染在屏幕最上层；
Screen Space - Camera：UI 通过指定相机渲染，Z 轴表示 “离相机的距离”，仍用像素坐标映射；
World Space：Canvas 是 3D 物体，UI 用世界坐标，需通过相机观察（适合 3D/2D 混合界面）。
根据上面三种模式的特点，可以知道，Screen Space - Overlay模式，UI的遮挡关系完全由其层级即sorting layer和sorting order决定，裁剪则只用看屏幕范围；Screen Space - Camera模式，canvas的位置是固定的，因此所有UI本身仍然遵循sorting layer和sorting order的规则。只不过，UI和模型之间还会经过相机的裁剪和深度控制；World Space：Canvas则完全可以将每一个canvas视为3D模型,canvas中的UI仍然以sorting layer和sorting order排序，而canvas和canvas以及模型之间，依赖相机的裁剪。因此2D的渲染相对3D会稍有简化，在Screen Space - Overlay模式下，不具有相机的处理过程，CPU会直接将UI的mesh等信息经过合批处理，组成DrawCall发送给GPU；而Screen Space - Camera和World Space：Canvas模式下的渲染则和3D模型没有太大区别。

3.针对UI的上述特征，我们就可以大致总结出canvas不同模式的适用情况了。Screen Space - Overlay更适用于类似开心消消乐、连连看等主体是2D的项目，或者3D模型只作为背景，不存在与UI穿插的情况；Screen Space - Camera比较适合3D游戏，UI和3D存在部分穿插的情况；而World Space：Canvas则适用于UI较少，且多为适用3D交互UI的项目。

那么回到最开始的问题，“我们有一个背包界面，左边显示角色模型，右边显示背包格子。 那么3D的模型是怎么显示在2D的UI上的？ 有哪些解决方案？”
对于UI而言，如果只有此处有3D模型展示，其他地方都是2D的情况，适合使用Screen Space - Overlay方式，这样只用考虑模型展示区域的位置、范围，其他地方只用关注UI之间的层级即可；而如果是一个比较传统的3D游戏，则更合适的UI渲染解决方案是Screen Space - Camera模式，这样可以更方便地解决2D和3D反复穿插地问题，同时也没有破坏UI原有的层级体系，后续可以相互独立地维护2D和3D展示；假如游戏中还存在一些比较特殊的UI面板，例如需要面板有旋转、在3D场景中可以交互的话，则要考虑引入World Space：Canvas的渲染模式，这种情况就要在项目立项之初，就设计好UI和模型间的位置关系、缩放比例等细节，后续维护也需要更加小心。
当UI的渲染解决方案采取的是Screen Space - Overla或Screen Space - Camera时，为了解决模型与UI的穿插问题，一种实现方式是将3D模型转换成2D元素，再与UI一起进行渲染。首先同样的，需要有一个相机来观测该3D模型，为了避免场景中的其他元素影响，可以对所有使用该相机观测的对象设置层级，即layer属性，然后该相机就只观测该layer下的对象，而剔除所有其他对象；之后，相机观测到的内容，不会经过传统的3D模型渲染流程，而是将其设置到一张我们创建的纹理上，即render texture，这样就完成了3D模型到2D的转换；而为了将该2D图像最终渲染到屏幕上，就需要将其融入现有的UI渲染流程中，像是普通2D图片需要借助image进行渲染一样，render texture需要借助raw image来进行渲染；当我们将关联好renderer texture的raw image节点，放在UI节点之中后，就完整的完成了从3D到2D的转换，之后所有内容就会按照2D UI的渲染流程，进行最终的显示。
不过需要注意的是，使用RT时会占据GPU内存，同时会增加绘制开销，因此除了特定情况下，例如模型需要和UI一起进行UI Mask裁剪；需要的模型是独立于其他3D对象，不希望被其他3D对象影响时；该3D模型需要单独后处理，不能做全局处理时。其他情况一般使用Screen Space - Camera直接渲染UI和3D模型即可解决大部分问题。

除了前面提到的UI和模型外，特效也是游戏中经常涉及的另一个视觉概念。广义上的特效涵盖很广，像上面描述中提到的满足项目美术风格用到的材质、shader就可以看成是特效的一种，此外粒子系统也是unity中比较常用的一种特效手段。
材质，顾名思义，这个概念和现实生活中材质的概念类似，例如日常中提到的金属材质、玻璃材质、木头材质等等；unity中的材质，可以简单地理解为一系列参数的集合，例如表面的粗糙程度、反光程度、对应的纹理贴图等等。而shader则是在GPU进行渲染时，对于材质中这些属性，进行组织、最终计算的过程。
粒子系统，其本质上也由传统的渲染对象组成的，只不过这个系统是按照设定的参数，在一定时间随机发射若干粒子，这些粒子就是一个个mesh对象，其渲染过程与之前描述的2DUI和3D模型完全相同。3D模型上的粒子系统，随模型本身的解决方案一起渲染即可，而UI上的粒子系统，考虑到UI本身会经常涉及位置、大小等变化，不适合采用RT的方式，因此直接与UI一起进行渲染，而此时需要注意单独处理粒子的渲染顺序、缩放、裁剪等问题。

在Screen Space - Camera模式下，UI和模型间的渲染顺序，遵循着sorting layer-sorting order-RenderQueue-Z轴距离（针对模型而言）-hierachy节点顺序（针对UI而言）的规则。一般而言，会将3D和UI在sorting layer上进行区别；UI之间会通过sorting order和hierachy控制，例如canvas和canvas之间使用sorting order区分渲染顺序，同一个canvas之间使用hierachy控制；当一个粒子和多个UI有着先后关系时，同一个canvas下的UI也更推荐使用sorting order来控制。而RenderQueue时更为底层的渲染顺序控制手段，通常是为了解决一些因透明引起的遮挡问题时手动设置，大多数情况下应尽量避免人为修改。

粒子的缩放问题，主要是因为UI在很多情况下，不需要手动设置缩放，而是会随着canvas和节点保持缩放，而这些行为在粒子系统以及3D模型的渲染中，并不会自动执行，最终就会导致UI和粒子系统的比例有问题，因此就需要编写代码，在粒子系统中，补全UI的缩放过程。以下是AI给出的一种粒子系统的缩放补偿方式：
```c#
using UnityEngine;
using UnityEngine.UI;

[RequireComponent(typeof(ParticleSystem))]
public class UIParticleScaleAdapter : MonoBehaviour
{
    [Header("适配参数")]
    [Tooltip("设计分辨率下的粒子初始尺寸（像素）")]
    public float designParticleSize = 20f; // 设计时的目标像素尺寸
    [Tooltip("是否适配粒子发射形状的缩放")]
    public bool adaptShapeScale = true;

    // 核心引用
    private ParticleSystem _particle;
    private Canvas _rootCanvas;
    private RectTransform _parentRect;
    private RectTransform _selfRect; // 自身UI节点（若有）

    // 初始参数（避免重复叠加缩放）
    private float _originalStartSize;
    private Vector3 _originalLocalScale;
    private Vector3 _originalShapeScale;

    void Start()
    {
        // 初始化引用
        _particle = GetComponent<ParticleSystem>();
        _rootCanvas = GetComponentInParent<Canvas>();
        _parentRect = GetComponentInParent<RectTransform>();
        _selfRect = GetComponent<RectTransform>();

        // 记录初始参数（基于设计分辨率）
        var mainModule = _particle.main;
        _originalStartSize = designParticleSize / _rootCanvas.scaleFactor; // 反推初始startSize
        mainModule.startSize = _originalStartSize;

        _originalLocalScale = transform.localScale;
        _originalShapeScale = adaptShapeScale ? _particle.shape.scale : Vector3.one;

        // 监听Canvas缩放变化（分辨率切换/Canvas.scaleFactor修改）
        if (_rootCanvas != null)
        {
            _rootCanvas.scaleFactorChanged += UpdateParticleScale;
            _rootCanvas.referencePixelsPerUnitChanged += UpdateParticleScale;
        }

        // 初始适配
        UpdateParticleScale();
    }

    void Update()
    {
        // 实时检测父节点缩放变化（低频检测，避免每帧计算）
        if (Input.GetKeyDown(KeyCode.Space)) // 可替换为自己的检测逻辑（如每帧/每0.1秒）
        {
            UpdateParticleScale();
        }
    }

    /// <summary>
    /// 核心：同步粒子缩放与UI缩放
    /// </summary>
    public void UpdateParticleScale(float _ = 0)
    {
        if (_rootCanvas == null || _parentRect == null) return;

        // 1. 计算UI的总缩放系数（Canvas全局缩放 + 父节点局部缩放）
        float canvasScale = _rootCanvas.scaleFactor;
        float parentScale = Mathf.Min(_parentRect.localScale.x, _parentRect.localScale.y); // 等比缩放，避免拉伸
        float totalScale = canvasScale * parentScale;

        // 2. 同步粒子核心尺寸（startSize）
        var mainModule = _particle.main;
        mainModule.startSize = _originalStartSize * totalScale;

        // 3. 同步粒子空间缩放（transform.localScale）
        transform.localScale = _originalLocalScale * totalScale;

        // 4. 同步粒子发射形状缩放（可选，如圆形/矩形发射范围）
        if (adaptShapeScale)
        {
            var shapeModule = _particle.shape;
            shapeModule.scale = _originalShapeScale * totalScale;
        }

        // 5. 若自身是UI节点，同步RectTransform缩放（可选）
        if (_selfRect != null)
        {
            _selfRect.localScale = Vector3.one * totalScale;
        }
    }

    // 销毁时移除监听，避免内存泄漏
    void OnDestroy()
    {
        if (_rootCanvas != null)
        {
            _rootCanvas.scaleFactorChanged -= UpdateParticleScale;
            _rootCanvas.referencePixelsPerUnitChanged -= UpdateParticleScale;
        }
    }

    // 编辑器下实时预览（可选，方便调试）
    void OnValidate()
    {
        if (Application.isPlaying) return;
        if (_particle == null) _particle = GetComponent<ParticleSystem>();
        _particle.main.startSize = designParticleSize;
    }
}
```
由于粒子系统与UI使用不同的渲染器，粒子系统使用particle renderer，UI使用canvas renderer，所以在处理了粒子与UI的渲染关系以及粒子缩放之后，需要考虑UI上的裁剪效果如何能适用于粒子系统。回顾GPU的渲染管线，基本需要经过顶点输入-顶点着色-透视除法-光栅化-片元着色-深度测试-模板测试-颜色混合/写入的流程，其中模板测试就是解决裁剪等问题的过程。其原理是，Mask会为该区域每个像素点提前写入一个标记值，称为stencil，当后续该区域像素点到达模板测试时，根据前序的stencil值来判断自身是否需要被渲染，是的话则继续渲染，否则就丢弃该像素点渲染。

了解了上述所有内容后，对于项目中遇到的特效无法看到的问题，可以尝试按照下面的流程进行排查：
1.该粒子特效是否在相机的有效视野中；
2.检查当前相机的渲染模式，如overlay模式下，UI会永远在最上层，导致粒子特效无法被看到；
3.查看当前UI及粒子特效的sorting layer和sorting order，如果UI层级更高的话，也是会遮挡粒子特效；
4.检查粒子特效是否在mask区域之外，或者设置的stencil存在问题，在渲染时被裁剪了；
5.检查特效所使用的材质、shader，是否符合当前项目的渲染规范，如透明对象未将ZWrite设置为Off的时候，该透明对象也会写入深度缓冲，导致本应在透明对象后面，可以被看到的对象，不能通过深度测试，最终没有被渲染。